{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-11-13T18:41:36.893430Z",
     "end_time": "2024-11-13T18:41:39.596065Z"
    }
   },
   "outputs": [],
   "source": [
    "#load in the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import re\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load in the different csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the aldi shape: (654, 14)\n",
      "this is the lidl shape: (1273, 34)\n",
      "this is the migros shape: (325, 11)\n"
     ]
    }
   ],
   "source": [
    "#define the directories of the three retailers\n",
    "\n",
    "path_aldi = \"C:\\\\Users\\\\41798\\\\Desktop\\\\CIP\\\\cip-gemuese\\\\aldi_transform.csv\"\n",
    "\n",
    "path_lidl = \"C:\\\\Users\\\\41798\\\\Desktop\\\\CIP\\\\cip-gemuese\\\\lidl_transform.csv\"\n",
    "\n",
    "path_migros = \"C:\\\\Users\\\\41798\\\\Desktop\\\\CIP\\\\cip-gemuese\\\\migros_scraper_parser_2024-11-11-Nov-19.csv\"\n",
    "\n",
    "#read in the data\n",
    "aldi_df = pd.read_csv(path_aldi, sep=\",\")\n",
    "lidl_df = pd.read_csv(path_lidl, sep=\";\")\n",
    "migros_df = pd.read_csv(path_migros, sep=\";\")\n",
    "\n",
    "#show the shape of the file\n",
    "\n",
    "print(\"aldi shape:\", aldi_df.shape)\n",
    "print(\"shape:\", lidl_df.shape)\n",
    "print(\"shape:\", migros_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-13T18:45:08.460942Z",
     "end_time": "2024-11-13T18:45:08.641837Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# unify the column names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_aldi_lidl: {'time', 'Swiss_product', 'price per 100g/pice', 'price', 'BIO', 'amount', 'name', 'main_category'}\n",
      "length common cols: 8\n",
      "only aldi: {'retailer', 'additional_info', 'sub_category', 'country_origin', 'category', 'price_per_amount'}\n",
      "only lidl: {'Is_last_char_9', 'Weight', 'Word_count', 'Title', 'Last_char_price', 'Discount_exist', 'Price_higher_avg', 'Review', 'Date', 'Unit', 'Url', 'Discount_end_date', 'Subcategory', 'Id', 'Price_before_discount', 'Discount_relative', 'Origin', 'Store', 'Timewindow_discount', 'Discount_start_date', 'Discount', 'Weight_unit', 'Discount_end_day', 'Brand', 'Discount_start_day', 'Discount_duration'}\n"
     ]
    }
   ],
   "source": [
    "#check if the column names are the same\n",
    "aldi_columns = set(aldi_df.columns)\n",
    "lidl_columns = set(lidl_df.columns)\n",
    "migros_columns = set(migros_df.columns)\n",
    "\n",
    "#check for the intersection\n",
    "#aldi dataframe is the template for column names\n",
    "#check manually which difference in aldi_only_cols and lidl_only_cols could fit together\n",
    "commen_cols = aldi_columns.intersection(lidl_columns)\n",
    "print(\"common_aldi_lidl:\", commen_cols)\n",
    "print(\"length common cols:\",len(commen_cols))\n",
    "aldi_only_cols = aldi_columns.difference(lidl_columns)\n",
    "print(\"only aldi:\", aldi_only_cols)\n",
    "lidl_only_cols = lidl_columns.difference(aldi_columns)\n",
    "print(\"only lidl:\", lidl_only_cols)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-13T19:02:22.591670Z",
     "end_time": "2024-11-13T19:02:22.598181Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "an important column is retailer in aldi which is missing in lidl columns. this kind of column is described as Store in the lidl dataset.As well as sub_category and country_origin is missing. which will be changed in the lidl dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_aldi_migros: {'additional_info', 'country_origin', 'price', 'category', 'BIO', 'amount', 'name', 'price_per_amount'}\n",
      "length common cols: 8\n",
      "only aldi: {'retailer', 'time', 'Swiss_product', 'sub_category', 'price per 100g/pice', 'main_category'}\n",
      "only migros: {'store', 'product_url', 'unit'}\n"
     ]
    }
   ],
   "source": [
    "#check for the column names between aldi and migros\n",
    "commen_cols = aldi_columns.intersection(migros_columns)\n",
    "print(\"common_aldi_migros:\", commen_cols)\n",
    "print(\"length common cols:\",len(commen_cols))\n",
    "aldi_only_cols = aldi_columns.difference(migros_columns)\n",
    "print(\"only aldi:\", aldi_only_cols)\n",
    "migros_only_cols = migros_columns.difference(aldi_columns)\n",
    "print(\"only migros:\", migros_only_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-13T19:03:38.742896Z",
     "end_time": "2024-11-13T19:03:38.836167Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In migros datset is the retailer also missing which is also described as store. the important column price per 100g/pice is described as price_per_amount in the migros dataset, which will be changed later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## change columns in lidl dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common cols: {'retailer', 'time', 'Swiss_product', 'sub_category', 'price per 100g/pice', 'country_origin', 'price', 'BIO', 'amount', 'name', 'main_category'}\n",
      "length common cols: 11\n"
     ]
    }
   ],
   "source": [
    "#in lidl change columns Origin-->country_origin, Subcategory--> sub_category, Store --> retailer\n",
    "#rename the columns\n",
    "\n",
    "lidl_df = lidl_df.rename(columns={\n",
    "    \"Origin\": \"country_origin\",\n",
    "    \"Subcategory\": \"sub_category\",\n",
    "    \"Store\": \"retailer\"\n",
    "})\n",
    "\n",
    "#check again if the intersection shows 3 more columns lidl\n",
    "#check if the column names are the same\n",
    "aldi_columns = set(aldi_df.columns)\n",
    "lidl_columns = set(lidl_df.columns)\n",
    "\n",
    "commen_cols = aldi_columns.intersection(lidl_columns)\n",
    "print(\"common cols:\", commen_cols)\n",
    "print(\"length common cols:\", len(commen_cols))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-13T19:12:41.356297Z",
     "end_time": "2024-11-13T19:12:41.419490Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now the length of the column cols increased by 3 which was expected. The columns in lidl data set Origin, Subcategory and Store were renamed after country_origin,\n",
    "sub_category and retailer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## change columns in migros dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common cols: {'retailer', 'additional_info', 'price per 100g/pice', 'country_origin', 'price', 'BIO', 'amount', 'name', 'main_category'}\n",
      "length common cols: 9\n"
     ]
    }
   ],
   "source": [
    "###rename the migros dataset\n",
    "###price_per_amount -->price per 100g/pice, store --> retailer, category --> main_categroy\n",
    "migros_df = migros_df.rename(columns={\n",
    "    \"price_per_amount\": \"price per 100g/pice\",\n",
    "    \"category\": \"main_category\",\n",
    "    \"store\": \"retailer\"\n",
    "})\n",
    "\n",
    "#check if the column names are the same\n",
    "aldi_columns = set(aldi_df.columns)\n",
    "migros_columns = set(migros_df.columns)\n",
    "\n",
    "commen_cols = aldi_columns.intersection(migros_columns)\n",
    "print(\"common cols:\", commen_cols)\n",
    "print(\"length common cols:\", len(commen_cols))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-13T19:25:17.056122Z",
     "end_time": "2024-11-13T19:25:17.087672Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "three column names were changed two of them were already in the common section so there is only one additional column after the changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# merge the dataset togther"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stores_combined_df = pd.concat([aldi_df.reset_index(drop=True), lidl_df.reset_index(drop=True), migros_df.reset_index(drop=True)], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# unify the data in the columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#change yes/no to Wahr/Falsch in BIO column\n",
    "\n",
    "\n",
    "stores_combined_df[\"BIO\"] = stores_combined_df[\"BIO\"].replace({\n",
    "    \"yes\": \"True\",\n",
    "    \"no\": \"False\",\n",
    "    \"True\" : \"True\",\n",
    "    \"False\": \"False\"\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the column 'BIO' the different datasets showed different values True and False. so this was changed that the values are True or False."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#change yes/no to Wahr/Falsch in BIO column\n",
    "\n",
    "print(stores_combined_df[\"Swiss_product\"])\n",
    "\n",
    "stores_combined_df[\"Swiss_product\"] = stores_combined_df[\"Swiss_product\"].replace({\n",
    "    \"yes\": \"True\",\n",
    "    \"no\": \"False\",\n",
    "    \"True\" : \"true\",\n",
    "    \"False\": \"False\",\n",
    "    \"unknown\": np.nan\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The column \"Swiss_product\" was unified as well to True or False or if not available to NA."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#change the main category all to lower cases\n",
    "\n",
    "stores_combined_df[\"main_category\"] = stores_combined_df[\"main_category\"].str.lower()\n",
    "\n",
    "#change the gemuse --> gemüse, fruchte --> obst, obst-&-gemüse --> gemüse\n",
    "# in the migros and aldi dataset was no umlaut which was changed and\n",
    "\n",
    "stores_combined_df[\"main_category\"] = stores_combined_df[\"main_category\"].replace({\"gemuse\":\"gemüse\", \"fruchte\":\"obst\", \"obst-&-gemüse\":\"gemüse\"})\n",
    "\n",
    "#change the time to only the date not with the daytime anymore\n",
    "\n",
    "#only keeps the format yyyy-mm-dd\n",
    "stores_combined_df[\"time\"] = stores_combined_df[\"time\"].str[:10]\n",
    "#changes to the datetime format\n",
    "stores_combined_df[\"time\"] = pd.to_datetime(stores_combined_df[\"time\"], errors='coerce').dt.date\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# quick check if the rows from each datasets equals to the merged dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"rows in the merged file:\" , len(stores_combined_df))\n",
    "print(\"rows all files together calculated\", len(migros_df) + len(lidl_df) + len(aldi_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# simplify the name to a simple name with llm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#define the api key and the llm model\n",
    "#for this purpose and also the pricing was gpt-3.5-turbo suffient\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "chat = ChatOpenAI(model_name = \"gpt-3.5-turbo\")\n",
    "\n",
    "#the input is a list from the merged dataset from the column name\n",
    "openai_lst = list(stores_combined_df[\"name\"])\n",
    "\n",
    "# create a empty list which will be later used as storage\n",
    "filtered_responses = []\n",
    "\n",
    "# create a prompt template for Chatgpt\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"Here is a single fruit or vegetable: {product}.\"\n",
    "             \"Please return only its simplified name without any other explanation.\"\n",
    "             \"For example, 'Schweizer Rockit Äpfel 400g, suisse garantie' should be just 'Apfel'.\"\n",
    "             \"Make sure the input length matches the output length exactly, and provide only the singular form.\"\n",
    "             \"Return the result as a single string, not a list.\"\n",
    ")\n",
    "\n",
    "# create a chain\n",
    "chain = LLMChain(llm=chat, prompt=prompt_template)\n",
    "\n",
    "# go through every element in the list and pass it to the llm\n",
    "for product_name in openai_lst:\n",
    "    print(\"Processing product:\", product_name)\n",
    "\n",
    "    # transfer product to the prompt\n",
    "    response = chain.run(product=product_name)\n",
    "    print(\"Response from ChatGPT:\", response)\n",
    "\n",
    "    # append the result to the list\n",
    "    filtered_responses.append(response.strip())\n",
    "    print(\"Filtered response so far:\", filtered_responses)\n",
    "    print(\"Current length of filtered responses:\", len(filtered_responses))\n",
    "\n",
    "# check the length of the response and\n",
    "print(\"Length of response list:\", len(filtered_responses))\n",
    "print(\"Length of dataset list:\", len(openai_lst))\n",
    "\n",
    "# create a new column with the simplified names as product_simple\n",
    "stores_combined_df[\"product_simple\"] = filtered_responses\n",
    "\n",
    "# check the new column\n",
    "print(stores_combined_df[\"product_simple\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The aim of this section is to simplify the the name for example 'Schweizer Rockit Äpfel 400g, suisse garantie' to just Apfel.\n",
    "For further analysis with the dataset this column 'product_simple' will be useful.\n",
    "In a first step a prompt template will be defined which should return the simple name for the product.\n",
    "with the the langchain package a chain is built and each element will be checked and the response saved in an empty list.\n",
    "The complete list will be the new column \"product_simple\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# write the merged file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stores_combined_df.to_excel(\"C:\\\\Users\\\\41798\\\\Desktop\\\\CIP\\\\cip-gemuese\\\\stores_combined_all.xlsx\", index=False)\n",
    "stores_combined_df.to_csv(\"C:\\\\Users\\\\41798\\\\Desktop\\\\CIP\\\\cip-gemuese\\\\stores_combined_all.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
